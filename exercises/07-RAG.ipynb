{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the Retrieval for a Retrieval Augmented Generation (RAG) Use Case\n",
    "Now that we have all our context information stored in SAP HANA Cloud Vector Store, we can start asking the LLM questions about SAP AI Services. This time the model will not respond from it's knowledge base, that is what it knows from it's training data but the retriever will check for relevant context information in our vector database and send that text chunk to the LLM to read through before responding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "with open('/home/user/projects/generative-ai-codejam/.aicore-config.json', 'r') as config_file:\n",
    "    config_data = json.load(config_file)\n",
    "\n",
    "os.environ[\"AICORE_AUTH_URL\"]=config_data[\"url\"]+\"/oauth/token\"\n",
    "os.environ[\"AICORE_CLIENT_ID\"]=config_data[\"clientid\"]\n",
    "os.environ[\"AICORE_CLIENT_SECRET\"]=config_data[\"clientsecret\"]\n",
    "os.environ[\"AICORE_BASE_URL\"]=config_data[\"serviceurls\"][\"AI_API_URL\"]\n",
    "os.environ[\"AICORE_RESOURCE_GROUP\"]=\"default\"\n",
    "\n",
    "from gen_ai_hub.proxy.langchain.openai import ChatOpenAI\n",
    "from gen_ai_hub.proxy.langchain.openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain_community.vectorstores.hanavector import HanaDB\n",
    "from hdbcli import dbapi\n",
    "\n",
    "import configparser\n",
    "import variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ SET the `EMBEDDING_TABLE` to `\"EMBEDDINGS_SAP_AI_SERVICES_>add your name here<\"` like in the previous exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are again connecting to our SAP HANA Cloud Vector Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('/home/user/projects/generative-ai-codejam/.user.ini')\n",
    "connection = dbapi.connect(\n",
    "    address=config.get('hana', 'url'), \n",
    "    port=config.get('hana', 'port'), \n",
    "    user=config.get('hana', 'user'),\n",
    "    password=config.get('hana', 'passwd'),\n",
    "    autocommit=True,\n",
    "    sslValidateCertificate=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for custom documents\n",
    "embeddings = OpenAIEmbeddings(deployment_id=variables.EMBEDDING_DEPLOYMENT_ID)\n",
    "db = HanaDB(\n",
    "    embedding=embeddings, connection=connection, table_name=variables.EMBEDDING_TABLE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we are defining which LLM to use during the retrieving process. We then also assign which database to retrieve information from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which model to use\n",
    "chat_llm = ChatOpenAI(deployment_id=variables.LLM_DEPLOYMENT_ID)\n",
    "\n",
    "# Create a retriever instance of the vector store\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ Now instead of sending the query directly to the LLM, you will create a `RetrievalQA` instance and handover the LLM and the database that should be used during the retrieval process. Now you can send your query to the `Retriever`.\n",
    "\n",
    "ğŸ‘‰ Try out different queries. You can ask anything you would like to know about the SAP AI Service - Data Attribute Recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What is the machine learning model behind the regression model template of Data Attribute Recommendation?', 'result': 'The machine learning model behind the regression model template of Data Attribute Recommendation is a generic neural network that seeks to minimize the mean squared error (MSE). The template is designed for single-label dataset schemas only and does not support multi-label dataset schemas.', 'source_documents': [Document(metadata={'source': 'documents/SAP-Help-Data-Attribute-Recommendation.pdf', 'page': 59}, page_content='10.3.1\\xa0\\xa0Model Templates\\nEach model template consists of a machine learning pipeline, where specific  data preprocessing rules and\\nmodel architectures are defined.  The model templates for Data Attribute Recommendation are generic\\ntechnical components that can be used in a variety of use cases, covering classification  and regression\\nscenarios. See below the available classification  and regression model templates.\\nName ID Description\\nAutoML 188df8b2-795a-48c1-8297\\n-37f37b25ea00A set of generic and traditional machine learning models for sin-\\ngle-label, multi-class classification  tasks. This template automati-\\ncally starts several experiments and searches for the best data\\npreparation and machine learning algorithms for a given dataset\\nwithin the defined  algorithm space. Use this model template for\\nsmall to medium sized classification  tasks.\\nSee also the blog post How does AutoML work in Data Attribute\\nRecommendation\\n .\\nGeneric 223abe0f-3b52-446f-927\\n3-f3ca39619d2cGeneric neural network for multi-label, multi-class classification.\\nThe number of inputs and outputs is derived from the dataset\\nschema. This model template is recommended for a generic mul-\\nticlass prediction use case.\\nHierarchical d7810207-\\nca31-4d4d-9b5a-841a644\\nfd81fGeneric neural network for hierarchical classification.  The number\\nof inputs and outputs is derived from the dataset schema. This\\nmodel template is recommended for the prediction of multiple\\nclasses that form a hierarchy (a product hierarchy, for example).\\nRegression bdbcd699-4419-40a5-\\nabb8-e7ad43dde49bGeneric neural network for regression that seeks to minimize the\\nmean squared error (MSE). This model template does not support\\nmulti-label dataset schemas. Use single-label dataset schemas\\nonly.\\nSee also the blog post Solving regression use-cases with Data\\nAttribute Recommendation\\n .\\n\\ue05c\\xa0Note\\nDifferent  model templates may provide different  prediction quality for the same dataset and use case.\\nIf you are not sure, which model template is the best for your use case, you can Ask a Question  in the\\nSAP Community\\n  using the tag Data Attribute Recommendation . Y ou can also train several models and\\ncompare the expected accuracy among them.\\n60 PUBLICData Attribute Recommendation\\nAPI Reference'), Document(metadata={'source': 'documents/SAP-Help-Data-Attribute-Recommendation.pdf', 'page': 3}, page_content='1 What Is Data Attribute Recommendation?\\nApply machine learning to predict and classify data records.\\nData Attribute Recommendation uses free text, numbers and categories as input to classify entities such as\\nproducts, stores and users into multiple classes and also to predict the value of missing numerical attributes\\nin your data records. Y ou can use Data Attribute Recommendation, for example, to classify incoming product\\ninformation and predict the price of commodities based on their description.\\nWith Data Attribute Recommendation you can:\\nâ€¢Automate and speed up data management processes\\nâ€¢Reduce errors and manual efforts  in data maintenance\\nâ€¢Increase data consistency and accuracy\\nFeatures\\nManage training dataPerform tasks related to the dataset that will be used to train the machine\\nlearning model.\\nManage machine learning\\nmodelPerform tasks related to the machine learning model that will be used to classify\\nentities and predict the missing attributes in your data records.\\nClassify data recordsClassify data records by specifying which deployed machine learning model\\nshould be used.\\nPredict data recordsPredict the value of missing numerical attributes in your data records by\\nspecifying which deployed machine learning model should be used.\\nBenefit  from\\nmultitenancy supportUse this service in tenant-aware (multitenant) applications. Run them on a shared\\ncompute unit that can be used by multiple consumers (tenants).\\nEnvironment\\nThis service is available in the following environments:\\nâ€¢Cloud Foundry environment\\nâ€¢Kyma environment\\n4 PUBLICData Attribute Recommendation\\nWhat Is Data Attribute Recommendation?')]}\n"
     ]
    }
   ],
   "source": [
    "# Create the QA instance to query llm based on custom documents\n",
    "qa = RetrievalQA.from_llm(llm=chat_llm, retriever=retriever, return_source_documents=True)\n",
    "\n",
    "# Send query\n",
    "query = \"What is the machine learning model behind the regression model template of Data Attribute Recommendation?\"\n",
    "\n",
    "print(qa.invoke(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ Go back to [06-store-embeddings-hana](06-store-embeddings-hana.ipynb) and try out different chunk sizes or different values for overlap. Store these chunks in a different table by adding a new variable to [variables.py](variables.py) and run this script again using the newly created table.\n",
    "\n",
    "[Next exercise](08-semantic-chunking.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
