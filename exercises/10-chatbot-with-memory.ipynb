{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot with Memory\n",
    "\n",
    "Let's add some history to the interaction and build a chatbot. Unlike many people think. LLMs are fixed in their state. They are trained until a certain cutoff date and do not know anything after that point unless you feed them current information. That is also why LLMs do not remember anything about you or the prompts you send to the model. If the model seems to remember you and what you said it is always because the application you are using (e.g. ChatPGT or the chat function in SAP AI Launchpad) is sending the chat history to the model to provide the conversation history to the model as context.\n",
    "\n",
    "Below you can find a simple implementation of a chatbot with memory.\n",
    "\n",
    "The code in this exercise is based on the [help documentation](https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/_reference/orchestration-service.html) of the Generative AI Hub Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import init_env\n",
    "import variables\n",
    "\n",
    "init_env.set_environment_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.message import Message, SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "    def __init__(self, orchestration_service: OrchestrationService):\n",
    "        self.service = orchestration_service\n",
    "        self.config = OrchestrationConfig(\n",
    "            template=Template(\n",
    "                messages=[\n",
    "                    SystemMessage(\"You are a helpful chatbot assistant.\"),\n",
    "                    UserMessage(\"{{?user_query}}\"),\n",
    "                ],\n",
    "            ),\n",
    "            llm=LLM(name=\"gemini-1.5-flash\"),\n",
    "        )\n",
    "        self.history: List[Message] = []\n",
    "\n",
    "    def chat(self, user_input):\n",
    "        response = self.service.run(\n",
    "            config=self.config,\n",
    "            template_values=[\n",
    "                TemplateValue(name=\"user_query\", value=user_input),\n",
    "            ],\n",
    "            history=self.history,\n",
    "        )\n",
    "\n",
    "        message = response.orchestration_result.choices[0].message\n",
    "\n",
    "        self.history = response.module_results.templating\n",
    "        self.history.append(message)\n",
    "\n",
    "        return message.content\n",
    "    \n",
    "    def reset(self):\n",
    "        self.history = []\n",
    "\n",
    "service = OrchestrationService(api_url=variables.AICORE_ORCHESTRATION_DEPLOYMENT_URL)\n",
    "bot = ChatBot(orchestration_service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm doing well, thank you for asking.  How can I help you today?\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.chat(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do not have access to real-time information, including weather. To get the weather for your location, please check a reliable weather app or website such as Google Weather, AccuWeather, or your local news.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Message(role=<Role.SYSTEM: 'system'>, content='You are a helpful chatbot assistant.'),\n",
       " Message(role=<Role.USER: 'user'>, content='Hello, how are you?'),\n",
       " Message(role=<Role.ASSISTANT: 'assistant'>, content=\"Hello! I'm doing well, thank you for asking.  How can I help you today?\\n\"),\n",
       " Message(role=<Role.SYSTEM: 'system'>, content='You are a helpful chatbot assistant.'),\n",
       " Message(role=<Role.USER: 'user'>, content=\"What's the weather like today?\"),\n",
       " Message(role=<Role.ASSISTANT: 'assistant'>, content='I do not have access to real-time information, including weather. To get the weather for your location, please check a reliable weather app or website such as Google Weather, AccuWeather, or your local news.\\n')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bot.chat(\"What's the weather like today?\"))\n",
    "bot.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, your first question was \"Hello, how are you?\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bot.chat(\"Can you remember what I first asked you?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to prove to you that the model does indeed not remember you, let's delete the history and try again :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a large language model, I have no memory of past conversations.  Each interaction with me starts fresh.  To help me assist you, please tell me what you'd like me to do now.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bot.reset()\n",
    "print(bot.chat(\"Can you remember what I first asked you?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Next exercise - OPTIONAL](11-ai-agents.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
