{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot with Memory\n",
    "\n",
    "Let's add some history to the interaction and build a chatbot. Unlike many people think. LLMs are fixed in their state. They are trained until a certain cutoff date and do not know anything after that point unless you feed them current information. That is also why LLMs do not remember anything about you or the prompts you send to the model. If the model seems to remember you and what you said it is always because the application you are using (e.g. ChatPGT or the chat function in SAP AI Launchpad) is sending the chat history to the model to provide the conversation history to the model as context.\n",
    "\n",
    "Below you can find a simple implementation of a chatbot with memory.\n",
    "\n",
    "The code in this exercise is based on the [help documentation](https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/_reference/orchestration-service.html) of the Generative AI Hub Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import init_env\n",
    "import variables\n",
    "from typing import List\n",
    "\n",
    "init_env.set_environment_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the packages you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.message import Message, SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the chatbot class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "    def __init__(self, orchestration_service: OrchestrationService):\n",
    "        self.service = orchestration_service\n",
    "        self.config = OrchestrationConfig(\n",
    "            template=Template(\n",
    "                messages=[\n",
    "                    SystemMessage(\"You are a helpful chatbot assistant.\"),\n",
    "                    UserMessage(\"{{?user_query}}\"),\n",
    "                ],\n",
    "            ),\n",
    "            # TODO add a model name here, e.g. gemini-1.5-flash\n",
    "            llm=LLM(name=\"\"),\n",
    "        )\n",
    "        self.history: List[Message] = []\n",
    "\n",
    "    def chat(self, user_input):\n",
    "        response = self.service.run(\n",
    "            config=self.config,\n",
    "            template_values=[\n",
    "                TemplateValue(name=\"user_query\", value=user_input),\n",
    "            ],\n",
    "            history=self.history,\n",
    "        )\n",
    "\n",
    "        message = response.orchestration_result.choices[0].message\n",
    "\n",
    "        self.history = response.module_results.templating\n",
    "        self.history.append(message)\n",
    "\n",
    "        return message.content\n",
    "    \n",
    "    def reset(self):\n",
    "        self.history = []\n",
    "\n",
    "service = OrchestrationService(api_url=variables.AICORE_ORCHESTRATION_DEPLOYMENT_URL)\n",
    "bot = ChatBot(orchestration_service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.chat(\"Hello, are you there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.chat(\"Do you like CodeJams?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.chat(\"Can you remember what we first talked about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to prove to you that the model does indeed not remember you, let's delete the history and try again :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.reset()\n",
    "bot.chat(\"Can you remember what we first talked about?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Next exercise - OPTIONAL](11-ai-agents.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
