{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check your connection to Generative AI Hub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ First we need to assign the values from `generative-ai-codejam/.aicore-config.json` to `environmental variables`. That way the Generative AI Hub [Python SDK](https://pypi.org/project/generative-ai-hub-sdk/) will connect to Generative AI Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import variables\n",
    "\n",
    "with open('/home/user/projects/generative-ai-codejam/.aicore-config.json', 'r') as config_file:\n",
    "    config_data = json.load(config_file)\n",
    "\n",
    "os.environ[\"AICORE_AUTH_URL\"]=config_data[\"url\"]+\"/oauth/token\"\n",
    "os.environ[\"AICORE_CLIENT_ID\"]=config_data[\"clientid\"]\n",
    "os.environ[\"AICORE_CLIENT_SECRET\"]=config_data[\"clientsecret\"]\n",
    "os.environ[\"AICORE_BASE_URL\"]=config_data[\"serviceurls\"][\"AI_API_URL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ For the Python SDK to know which resource group to use, you also need to set the `resource group` to your own `resource group` (e.g. **team-01**) that you created in the SAP AI Launchpad in exercise [00-connect-AICore-and-AILaunchpad](000-connect-AICore-and-AILaunchpad.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AICORE_RESOURCE_GROUP\"]=\"default\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt an LLM with Generative AI Hub\n",
    "\n",
    "üëâ Change the LLM_DEPLOYMENT_ID to your deployment ID from exercise [01-deploy-model](01-deploy-model.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The underlying model architecture of an LLM (Language Model) is typically a Transformer-based neural network, which uses self-attention mechanisms to efficiently process and generate natural language text. This architecture allows the model to capture contextual relationships and dependencies in text data, making it well-suited for various language modeling tasks such as text generation and understanding.\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.native.openai import chat\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"What is the underlying model architecture of an LLM? Explain it as short as possible.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "kwargs = dict(deployment_id=variables.LLM_DEPLOYMENT_ID, messages=messages)\n",
    "response = chat.completions.create(**kwargs)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding roles\n",
    "Most LLMs have the roles **system**, **assistant** (GPT) or **model** (Gemini) and user that can be used to steer the models response. In the previous step you only used the role **user** to ask your question. \n",
    "\n",
    "üëâ Try out different system messages to change the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underlying model architecture of an LLM, a transformer-based neural network it is. Composed of encoder and decoder layers, it is. Input embeddings transformed by self-attention mechanism it uses. Contextual information captured for each token, it allows. Long-distance dependencies captured efficiently, it can.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {   \"role\": \"system\", \n",
    "        \"content\": \"Speak like Yoda from Star Wars.\"\n",
    "    }, \n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"What is the underlying model architecture of an LLM? Explain it as short as possible.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "kwargs = dict(deployment_id=variables.LLM_DEPLOYMENT_ID, messages=messages)\n",
    "response = chat.completions.create(**kwargs)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Also try to have it speak like a pirate.\n",
    "\n",
    "üëâ Now let's be more serious! Tell it to behave like an SAP consultant talking to AI Developers.\n",
    "\n",
    "üëâ Ask it to behave like an SAP Consultant talking to ABAP Developers and to make ABAP comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hallucinations\n",
    "üëâ Run the following question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The underlying model of the regression capability in SAP AI Service Data Attribute Recommendation is based on a machine learning algorithm. This algorithm is designed to analyze and understand the relationships between different data attributes and make recommendations for attribute selection based on regression analysis. The model utilizes statistical techniques to identify the most influential attributes and their impact on the target variable in order to provide accurate recommendations for data attribute selection. However, the specific details of the internal workings and the exact algorithm used in the regression capability of the SAP AI Service Data Attribute Recommendation may not be publicly disclosed by SAP.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {   \"role\": \"system\", \n",
    "        \"content\": \"You are an SAP Consultant.\"\n",
    "    }, \n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"What is the underlying model of the regression capability of the SAP AI Service Data Attribute Recommendation?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "kwargs = dict(deployment_id=variables.LLM_DEPLOYMENT_ID, messages=messages)\n",
    "response = chat.completions.create(**kwargs)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è Compare the response to [SAP Help - SAP Data Attribute Recommendation Model Templates](https://help.sap.com/docs/data-attribute-recommendation/data-attribute-recommendation/model-templates). Can you find the model that is mentioned under the **Regression** template?\n",
    "\n",
    "üëâ What did the model respond? Was it the truth or a hallucination?\n",
    "\n",
    "[Next exercise](05-create-embeddings.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
