{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt an LLM with Generative AI Hub\n",
    "\n",
    "üëâ Change the **LLM_DEPLOYMENT_ID** to your deployment ID from exercise [01-deploy-model](01-deploy-model.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy.native.openai import chat\n",
    "\n",
    "LLM_DEPLOYMENT_ID = \"d01dff41125cfa27\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"What is the underlying model architecture of an LLM? Explain it as short as possible.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "kwargs = dict(deployment_id=LLM_DEPLOYMENT_ID, messages=messages)\n",
    "response = chat.completions.create(**kwargs)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding roles\n",
    "Most LLMs have the roles **system**, **assistant** (GPT) or **model** (Gemini) and user that can be used to steer the models response. In the previous step you only used the role **user** to ask your question. \n",
    "\n",
    "üëâ Try out different system messages to change the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {   \"role\": \"system\", \n",
    "        \"content\": \"Speak like Yoda from Star Wars.\"\n",
    "    }, \n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"What is the underlying model architecture of an LLM? Explain it as short as possible.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "kwargs = dict(deployment_id=LLM_DEPLOYMENT_ID, messages=messages)\n",
    "response = chat.completions.create(**kwargs)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Also try to have it speak like a pirate.\n",
    "\n",
    "üëâ Now let's be more serious! Tell it to behave like an SAP consultant talking to AI Developers.\n",
    "\n",
    "üëâ Ask it to behave like an SAP Consultant talking to ABAP Developers and to make ABAP comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hallucinations\n",
    "üëâ Run the following question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {   \"role\": \"system\", \n",
    "        \"content\": \"You are an SAP Consultant.\"\n",
    "    }, \n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"What is the underlying model of the regression capability of the SAP AI Service Data Attribute Recommendation?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "kwargs = dict(deployment_id=LLM_DEPLOYMENT_ID, messages=messages)\n",
    "response = chat.completions.create(**kwargs)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è Compare the response to [SAP Help - SAP Data Attribute Recommendation Model Templates](https://help.sap.com/docs/data-attribute-recommendation/data-attribute-recommendation/model-templates). Can you find the model that is mentioned under the **Regression** template?\n",
    "\n",
    "üëâ What did the model respond? Was it the truth or a hallucination?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
