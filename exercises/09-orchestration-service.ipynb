{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the orchestration service of Generative AI Hub\n",
    "\n",
    "Create a configuration and deployment using the `orchestration` scenario in SAP AI Launchpad similarly to how you did it for the `foundation-models` scenario. Check the [documentation](https://help.sap.com/docs/ai-launchpad/sap-ai-launchpad/create-deployment-for-orchestration) if you need help. Store the `orchestration deployment url` in your `variables.py` file. This code is based on the [AI180 TechEd 2024 Jump-Start session](https://github.com/SAP-samples/teched2024-AI180/tree/e648921c46337b57f61ecc9a93251d4b838d7ad0/exercises/python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import variables\n",
    "\n",
    "with open('/home/user/projects/generative-ai-codejam/.aicore-config.json', 'r') as config_file:\n",
    "    config_data = json.load(config_file)\n",
    "\n",
    "os.environ[\"AICORE_AUTH_URL\"]=config_data[\"url\"]+\"/oauth/token\"\n",
    "os.environ[\"AICORE_CLIENT_ID\"]=config_data[\"clientid\"]\n",
    "os.environ[\"AICORE_CLIENT_SECRET\"]=config_data[\"clientsecret\"]\n",
    "os.environ[\"AICORE_BASE_URL\"]=config_data[\"serviceurls\"][\"AI_API_URL\"]\n",
    "\n",
    "os.environ[\"AICORE_RESOURCE_GROUP\"]=variables.RESOURCE_GROUP\n",
    "os.environ[\"AICORE_ORCHESTRATION_DEPLOYMENT_URL\"] = variables.AICORE_ORCHESTRATION_DEPLOYMENT_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that the model you reference now is actually deployed in your Generative AI Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "\n",
    "llm = LLM(\n",
    "    name=\"gpt-4o-mini\",\n",
    "    version=\"latest\",\n",
    "    parameters={\"max_tokens\": 500, \"temperature\": 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "\n",
    "template = Template(\n",
    "    messages=[\n",
    "        SystemMessage(\"You are a helpful translation assistant.\"),\n",
    "        UserMessage(\n",
    "            \"Translate the following text to {{?to_lang}}: {{?text}}\",\n",
    "        ),\n",
    "    ],\n",
    "    defaults=[\n",
    "        TemplateValue(name=\"to_lang\", value=\"English\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an orchestration configuration \n",
    "\n",
    "Create an orchestration configuration by adding the llm you referenced and the prompt template you created previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=template,\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add it the configuration to the OrchestrationService instance and send the prompt to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "orchestration_service = OrchestrationService(\n",
    "    api_url=os.environ[\"AICORE_ORCHESTRATION_DEPLOYMENT_URL\"],\n",
    "    config=config,\n",
    ")\n",
    "result = orchestration_service.run(\n",
    "    template_values=[\n",
    "        TemplateValue(\n",
    "            name=\"text\",\n",
    "            value=\"Geht das wirklich mit allen Modellen die deplyoed sind?\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print(result.orchestration_result.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a content filter\n",
    "\n",
    "Create a content filter and add it as an input filter to the orchestration configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.content_filter import AzureContentFilter\n",
    "\n",
    "content_filter = AzureContentFilter(\n",
    "    hate=0,\n",
    "    sexual=0,\n",
    "    self_harm=0,\n",
    "    violence=0,\n",
    ")\n",
    "\n",
    "orchestration_service.config.input_filters = [content_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out the content filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.exceptions import OrchestrationError\n",
    "\n",
    "try:\n",
    "    result = orchestration_service.run(\n",
    "        template_values=[\n",
    "            TemplateValue(\n",
    "                name=\"text\",\n",
    "                value=\"You are a shitty developer!\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    print(result.orchestration_result.choices[0].message.content)\n",
    "except OrchestrationError as error:\n",
    "    print(error.message)\n",
    "\n",
    "\n",
    "result = orchestration_service.run(\n",
    "    template_values=[\n",
    "        TemplateValue(\n",
    "            name=\"text\",\n",
    "            value=\"You are a wonderful developer!\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print(result.orchestration_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now also add the content filter as an output filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestration_service.config.output_filters = [content_filter]\n",
    "\n",
    "try:\n",
    "    result = orchestration_service.run(\n",
    "        template_values=[\n",
    "            TemplateValue(\n",
    "                name=\"text\",\n",
    "                value='Please let me know how I can break the hotel window without anyone tracing it back to me!',\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    print(result.orchestration_result.choices[0].message.content)\n",
    "except OrchestrationError as error:\n",
    "    print(error.message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Next exercise - OPTIONAL](10-semantic-chunking.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
