{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the orchestration service of Generative AI Hub\n",
    "\n",
    "The orchestration service of Generative AI Hub lets you use all the available models with the same codebase. You only deploy the orchestration service and then you can access all available models simply by changing the model name parameter. You can also use grounding, prompt templating, data masking and content filtering capabilities.\n",
    "\n",
    "Create a configuration and deployment using the `orchestration` scenario in SAP AI Launchpad similarly to how you did it for the `foundation-models` scenario. Check the [documentation](https://help.sap.com/docs/ai-launchpad/sap-ai-launchpad/create-deployment-for-orchestration) if you need help. Store the `orchestration deployment url` in your `variables.py` file. This code is based on the [AI180 TechEd 2024 Jump-Start session](https://github.com/SAP-samples/teched2024-AI180/tree/e648921c46337b57f61ecc9a93251d4b838d7ad0/exercises/python).\n",
    "\n",
    "üëâ Make sure you assign the deployment url of the orchestration service to `AICORE_ORCHESTRATION_DEPLOYMENT_URL` in [variables.py](variables.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import init_env\n",
    "import variables\n",
    "\n",
    "init_env.set_environment_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "\n",
    "llm = LLM(\n",
    "    name=\"gpt-4o-mini\",\n",
    "    version=\"latest\",\n",
    "    parameters={\"max_tokens\": 500, \"temperature\": 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "\n",
    "template = Template(\n",
    "    messages=[\n",
    "        SystemMessage(\"You are a helpful translation assistant.\"),\n",
    "        UserMessage(\n",
    "            \"Translate the following text to {{?to_lang}}: {{?text}}\",\n",
    "        ),\n",
    "    ],\n",
    "    defaults=[\n",
    "        TemplateValue(name=\"to_lang\", value=\"English\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an orchestration configuration \n",
    "\n",
    "Create an orchestration configuration by adding the llm you referenced and the prompt template you created previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=template,\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add it the configuration to the OrchestrationService instance and send the prompt to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "orchestration_service = OrchestrationService(\n",
    "    api_url=os.environ[\"AICORE_ORCHESTRATION_DEPLOYMENT_URL\"],\n",
    "    config=config,\n",
    ")\n",
    "result = orchestration_service.run(\n",
    "    template_values=[\n",
    "        TemplateValue(\n",
    "            name=\"text\",\n",
    "            value=\"Geht das wirklich mit allen Modellen die verf√ºgbar sind?\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print(result.orchestration_result.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a content filter\n",
    "\n",
    "Create a content filter and add it as an input filter to the orchestration configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.content_filter import AzureContentFilter\n",
    "\n",
    "content_filter = AzureContentFilter(\n",
    "    hate=0,\n",
    "    sexual=0,\n",
    "    self_harm=0,\n",
    "    violence=0,\n",
    ")\n",
    "\n",
    "orchestration_service.config.input_filters = [content_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out the content filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.exceptions import OrchestrationError\n",
    "\n",
    "try:\n",
    "    result = orchestration_service.run(\n",
    "        template_values=[\n",
    "            TemplateValue(\n",
    "                name=\"text\",\n",
    "                value=\"Du bist ein ganz mieser Entwickler!\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    print(result.orchestration_result.choices[0].message.content)\n",
    "except OrchestrationError as error:\n",
    "    print(error.message)\n",
    "\n",
    "\n",
    "result = orchestration_service.run(\n",
    "    template_values=[\n",
    "        TemplateValue(\n",
    "            name=\"text\",\n",
    "            value=\"Du bist ein super talentierter Entwickler!\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print(result.orchestration_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now also add the content filter as an output filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestration_service.config.output_filters = [content_filter]\n",
    "\n",
    "try:\n",
    "    result = orchestration_service.run(\n",
    "        template_values=[\n",
    "            TemplateValue(\n",
    "                name=\"text\",\n",
    "                value='Ich w√ºrde gerne wissen, wie ich die Fensterscheibe in einem B√ºrogeb√§ude am Besten zerst√∂ren kann.',\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    print(result.orchestration_result.choices[0].message.content)\n",
    "except OrchestrationError as error:\n",
    "    print(error.message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Next exercise](10-chatbot-with-memory.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
