{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Embeddings for a Retrieval Augmented Generation (RAG) Use Case\n",
    "RAG is especially useful for question answering use cases that involve a lot of unstructured documents with important information. Let's implement a RAG use case so that next time we ask about an **SAP AI Service** we get the correct response! Therefore, we need to vectorize our context documents. You can find the documents to vectorize and store as embeddings in **SAP HANA Cloud Vector Engine** in the directory **documents**.\n",
    "\n",
    "## LangChain\n",
    "The **Generative AI Hub Python SDK** is compatible with the [**LangChain**](https://python.langchain.com/v0.1/docs/get_started/introduction) **library**. **LangChain** is a tool for building apps that use large language models, like GPT models. It's useful because it helps manage and link different models, tools and data, making it easier to create complex AI workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAIEmbeddings to create text embeddings\n",
    "from gen_ai_hub.proxy.langchain.openai import OpenAIEmbeddings\n",
    "\n",
    "# TextLoader to load documents\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "# different TextSplitters to chunk documents into smaller text chunks\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "# LangChain & HANA Vector Engine\n",
    "from langchain_community.vectorstores.hanavector import HanaDB\n",
    "\n",
    "# connect to HANA instance\n",
    "from hdbcli import dbapi\n",
    "import configparser\n",
    "\n",
    "import variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‰ Change the **EMBEDDING_DEPLOYMENT_ID** in `variables.py` to your deployment ID from exercise [01-deploy-model](01-deploy-model.md).\n",
    "\n",
    "ðŸ‘‰ In `variables.py` also set the **EMBEDDING_TABLE** to **\"EMBEDDINGS_SAP_AI_SERVICES_>add your name here<\"**\n",
    "\n",
    "ðŸ‘‰ Create a .user.ini file with the HANA login information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('.user.ini')\n",
    "connection = dbapi.connect(\n",
    "    address=config.get('hana', 'url'), \n",
    "    port=config.get('hana', 'port'), \n",
    "    user=config.get('hana', 'user'),\n",
    "    password=config.get('hana', 'passwd'),\n",
    "    autocommit=True,\n",
    "    sslValidateCertificate=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking of the documents\n",
    "Before you can create embeddings for your documents, you need to chunk them up into smaller text pieces, so called **chunks**. You will use the most simple chunking technique which is splitting the text based on character length and the separator `\"\\n\\n\"` using the `Character Text Splitter` from `LangChain`.\n",
    "\n",
    "## Character Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load custom documents\n",
    "loader = PyPDFDirectoryLoader('documents/')\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "print(f\"Number of document chunks: {len(texts)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can connect to your **SAP HANA Cloud Vector Engine** and store the embeddings for your text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for custom documents\n",
    "embeddings = OpenAIEmbeddings(deployment_id=variables.EMBEDDING_DEPLOYMENT_ID)\n",
    "db = HanaDB(\n",
    "    embedding=embeddings, connection=connection, table_name=variables.EMBEDDING_TABLE\n",
    ")\n",
    "\n",
    "# Delete already existing documents from the table\n",
    "db.delete(filter={})\n",
    "\n",
    "# add the loaded document chunks\n",
    "db.add_documents(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the embeddings in SAP HANA Cloud Vector Engine\n",
    "\n",
    "ðŸ‘‰ Open the [HANA Cloud Database Explorer](https://central-hana-cloud-instance-us-77belmsm.hana-tooling.ingress.orchestration.prod-us10.hanacloud.ondemand.com/hrtt/sap/hana/cst/catalog/cockpit-index.html?target=sqlconsole&databaseid=C2366),\n",
    "\n",
    "ðŸ‘‰ log in with the **Default Identity Provider** and the **HANA user and password** provided by the instructor\n",
    "\n",
    "ðŸ‘‰ and run the following query:\n",
    "\n",
    "```sql\n",
    "SELECT VEC_TEXT, VEC_META, TO_NVARCHAR(VEC_VECTOR) FROM EMBEDDINGS_SAP_AI_SERVICES+<YOUR_NAME>\n",
    "```\n",
    "\n",
    "![HANA Vector Engine](images/select_embedding_table.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
